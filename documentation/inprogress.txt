- Research physical memory, virtual memory, pagetables
	* Best way to make a direct physical map
	* How to manipulate the pagetables
	* Allocators!

	1) Implement the pages themselves
		1a) Page Table                   Entry
		1b) Page Directory               Entry
		1c) Page Directory Pointer Table Entry
		1d) Page Map Level 4             Entry

		# Page Table Entry

			 0       Present                           bit [P]
			 1       Read/Write                        bit [R/W]
			 2       User/Supervisor          selector bit [U/S]
			 3       Write-Through/Write-Back selector bit [PWT]
			 4       Cache disable                     bit [PCD]
			 5       Accessed                          bit [A]
			 6       Dirty                             bit [D]
			 7       Page Attribute Table              bit [PAT]
			 8       Global                            bit [G]
			 9 : 11  (Available for OS use)
			12 : M-1 Physical page upper bits (12:(M-1))
			 M : 51  Reserved
			52 : 58  (Available for OS use)
			59 : 62  Protection Key                        [PK] := 0
			63       Execute disable                       [XD]

		According to osdev, if PAT is enabled, the PAT, PWT and PCD bits are
		repurposed as a three-bit index into the PAT MSR register, which offers
		more caching options, in PAT:PCD:PWT order.

		Limine furthers configures the PAT MSR with the following values:

			PAT0 -> WB
			PAT1 -> WT
			PAT2 -> UC-
			PAT3 -> UC
			PAT4 -> WP
			PAT5 -> WC
			PAT6 -> unspecified
			PAT7 -> unspecified

		Thus, the following caching combinations are possible:

			PAT = 0, PCD = 0, PWT = 0 → Write-Back
			PAT = 0, PCD = 0, PWT = 1 → Write-Through
			PAT = 0, PCD = 1, PWT = 0 → Uncacheable (overridable)
			PAT = 0, PCD = 1, PWT = 1 → Uncacheable
			PAT = 1, PCD = 0, PWT = 0 → Write-Protect
			PAT = 1, PCD = 0, PWT = 1 → Write-Combining
			PAT = 1, PCD = 1, PWT = 0 is UB
			PAT = 1, PCD = 1, PWT = 1 is UB

		Protection key support should be disabled by default.

		https://wiki.osdev.org/Paging#PAT
		https://github.com/limine-bootloader/limine/blob/v7.x/PROTOCOL.md

		# Page Directory Entry

			 0       Present                           bit [P]
			 1       Read/Write                        bit [R/W]
			 2       User/Supervisor          selector bit [U/S]
			 3       Write-Through/Write-Back selector bit [PWT]
			 4       Cache disable                     bit [PCD]
			 5       Accessed                          bit [A]
			 6       (Available for OS use)
			 7       Page Size                             [PS]  := 0
			 8 : 11  (Available for OS use)
			12 : M-1 Physical page upper bits (12:(M-1))
			 M : 51  Reserved
			52 : 62  (Available for OS use)
			63       Execute disable                  bit  [XD]

		# Page Directory Pointer Table Entry

			Identical to PDE.

		# Page Map Level 4 Entry

			Identical to PDE, but bit 7 (PS) is reserved.

		"M signifies the physical address width supported by a processor using
		PAE. Currently, up to 52 bits are supported, but the actual supported wi-
		dth may be less. "

		M can be calculated by executing the CPUID.80000008h:EAX[7:0] instruc-
		tion.

		Current layout is as follows:

			- A bunch of random mappings all over the place, known only by phys-
			map_descriptor.
			- Our kernel, at 0xfffffff800000000. Physical location given by Limine.
			- Supposedly, the HHDM should be a higher half direct physical -> virtual
			mapping given by Limine, however nothing I do makes it actually be
			in the higher half of the addressing space. Thus, we'll not use it.

		Our goal is:

			- Unmap everything from positive 128TiB region, making space for
			userspace.
			- Map the following in the negative 128TiB region:

				* Our higher half direct map (self made, not Limine's) (len 64TiB) (512GiB actual)
				  @ 0xffff'9000'0000'0000 until 0xffff'dfff'ffff'ffff

				* physframestack @ 0xffff'f000'0000'0000 (len (PHYS_AMNT / 4KiB) * 8 [MAX 128GiB]) (2MiB max actual)
				             until 0xffff'f01f'ffff'ffff

				* Our kernel     @ 0xffff'ffff'8000'0000 (len 64MiB  0x0400'0000)
				             until 0xffff'ffff'83ff'fff
				* vmalloc area   @ 0xffff'ffff'8400'0000 (len 256MiB 0x1000'0000)
				             until 0xffff'ffff'93ff'ffff

		To convert a virtual address to a physical address, you take it, subdiv-
		ive the address into the respective pagetable indices, walk it and then
		retrieve the physical address.

		"vmalloc area" is the virtual address range where all memory allocated
		for kernel use shall be put into. As the name suggest, the vmalloc() se-
		ries of calls are responsable for this region. Userspace allocations will
		be handled separately.

		"physpage stack" is where we will put the physical memory page metadata.
		As the name indicates, version 1 of Dagger will use a stack to manage
		physical memory. As per osdev, "The address of each available physical
		frame is stored in a stack-like dynamic structure. Allocating a page is
		fast (O(1)), freeing a page too but checking the state of a page is not
		practical, unless additional metadata is sorted by physical address."

		https://wiki.osdev.org/Page_Frame_Allocation

		The following functions shall define our paging api:

			- int punmap_frames(size_t count, void* virt, void* phys[]);
			/**
			 * int punmap_frames (size_t count, void* virt, void** phys); -- Unmap `count` virtual address pages and store respective physical pages on `phys`.
			 *
			 * This function is used to disassociate physical memory from virtual memory. It unmaps any
			 * virtual memory starting at `virt` up to `virt + PAGE_SIZE * count` and stores the physical address
			 * once-pointed-by in the array pointed by `phys`.
			 *
			 * If `phys` is NULL the physical addresses are not stored.
			 *
			 * Errors:
			 *  EINVAL - `virt` is NULL; `count` is zero.
			 *  EFAULT - Either `virt` or `phys` are not aligned to PAGE_SIZE.
			 *
			 */

			- int pmap_frames(size_t count, void* virt, void* phys[]);
			/**
			 * int pmap_frames(size_t count, void* virt, void* phys[]); -- Map `count` virtual address pages into `count` physical frames.
			 *
			 * This function is used to map a series of non-contiguous physical frames into a equally sized and
			 * contiguous virtual address range. It applies to the page tables immediatly.
			 *
			 * Errors:
			 *  EINVAL - Either `virt` or `phys` are NULL, and element of `phys` is NULL or `count` is zero.
			 *  EFAULT - Either `virt` or `phys` are not aligned to PAGE_SIZE.
			 *
			 * Example:
			 * {
			 *     // Preferably one should check if pop_frame() actually returned memory.
			 *     void* phys[4];
			 *     phys[0] = pop_frame();
			 *     phys[1] = pop_frame();
			 *     phys[2] = pop_frame();
			 *     phys[3] = pop_frame();
			 *     int err = pmap_frames(4, 0xcafe0000, phys);
			 *     // Assuming pmap_frames() succeded, `0xdeadcafe` is now a valid address
			 *     // pointing to four contiguous pages of virtual memory, backed by four frames of physical memory.
			 *     ((int*) phys[0]) = 1234;
			 * }
			 */

			- int pmap_frame_range(size_t count, void* virt, void* phys);
			/**
			 * int pmap_frame_range (size_t count, void* virt, void* phys); -- Map `count` virtual address pages to the contiguous physical memory `phys`.
			 *
			 * This function is used to map a physical memory range into a virtual address range.
			 * It maps `count` contiguous frames starting at `phys` into a contiguous range starting
			 * at `virt`. It applies to the page tables immediatly.
			 *
			 * Errors:
			 *  EINVAL - Either `virt` or `phys` are NULL or `count` is zero.
			 *  EFAULT - Either `virt` or `phys` are not aligned to PAGE_SIZE.
			 *
			 * Example:
			 * {
			 *     // Assume 0xf00fb000 is the physical address of some hardware register
			 *     // Assume 0xff..f000 is an previously allocated virtual address.
			 *     // Both are four pages long
			 *     void* phys = 0xf00fb000, *virt = 0xff..f000;
			 *     int err = pmap_frame_range(4, virt, phys);
			 * }
			 */

			- void* pg_peek(void* vaddr);
				This function will check the pagetable entry that populates virtual address
				'vaddr' and return it's physical address. It shall return NULL if 'vaddr' is not
				mapped.

			Next is some architecture specific function prototypes, not to be documented here:

				x86pg_map_frames      (void* virt_begin, void* virt_end, void* phys[],     struct pgdesc* desc)
				x86pg_map_frame_range (void* virt_begin, void* virt_end, void* phys_begin, struct pgdesc* desc)
				x86pg_unmap_frames    (void* virt_begin, void* virt_end, void* phys[])

				__pml4_map_frames (struct pml4e pml4[], void* virt_begin, void* virt_end, void* phys[], struct pgdesc* desc)
				__pdpt_map_frames (struct pdpte pdpt[], void* virt_begin, void* virt_end, void* phys[], struct pgdesc* desc, size_t pidx)
				__pd_map_frames   (struct pde   pd  [], void* virt_begin, void* virt_end, void* phys[], struct pgdesc* desc, size_t pidx)
				__pt_map_frames   (struct pte   pt  [], void* virt_begin, void* virt_end, void* phys[], struct pgdesc* desc, size_t pidx)

				__pml4_unmap_frames (struct pml4e pml4[], void* virt_begin, void* virt_end, void* phys[])
				__pdpt_unmap_frames (struct pdpte pdpt[], void* virt_begin, void* virt_end, void* phys[], size_t pidx)
				__pd_unmap_frames   (struct pde   pd  [], void* virt_begin, void* virt_end, void* phys[], size_t pidx)
				__pt_unmap_frames   (struct pte   pt  [], void* virt_begin, void* virt_end, void* phys[], size_t pidx)

				// Contiguous
				__pml4_map_frame_range (struct pml4e pml4[], void* virt_begin, void* virt_end, void* phys_begin, struct pgdesc* desc)
				__pdpt_map_frame_range (struct pdpte pdpt[], void* virt_begin, void* virt_end, void* phys_begin, struct pgdesc* desc)
				__pd_map_frame_range   (struct pde   pd  [], void* virt_begin, void* virt_end, void* phys_begin, struct pgdesc* desc)
				__pt_map_frame_range   (struct pte   pt  [], void* virt_begin, void* virt_end, void* phys_begin, struct pgdesc* desc)

//				__reload_cr3(void);
				struct pagetable_pml4_entry* __read_cr3(void);
				void __write_cr3(struct pagetable_pml4_entry* root);

		The following functions shall define our physpage api:
			
			- void  __x86_enumerate_frames(size_t count, void* start);
				This will push 'count' pages into the framstack,
				with the phys addr starting at `start`. Region must be
				contiguous.

				This function can fail silently. Exacerbate caution.

				'start' must be aligned to 4KiB. 'count' must be non-zero. The
				entire region denoted by 'start:count' must point to a valid set
				of free and unmanaged physical pages.

			- void* pop_frame(void)
				/**
				 * void* pop_frame(void); -- Pop a frame from the framestack.
				 *
				 * This function pops a physical memory frame from the framestack and returns it.
				 * It is the lowest operation used to allocate physical memory.
				 *
				 * On failure; an empty stack, this function returns NULL, and indicates the system
				 * is out of physical memory.
				 * Example:
				 * {
				 *     // The result address is physical and is not mapped into the virtual addressing space.
				 *     // You must map it to use it.
				 *     void* phys_addr = pop_frame();
				 *     if (phys_addr == NULL)
				 *         // handle oom //;
				 * }
				 */

			- int push_frame(void* phys)
				/**
				 * int push_frame(void* phys); -- Push a frame to the framestack.
				 *
				 * This function pushes the physical frame `phys` into the framestack.
				 *
				 * You must not push more frames into the framestack than there are physical frames in the machine, e.g.
				 * you must not call more `push_frame()`s than `pop_frame()`s.
				 *
				 * Addresses fed into push_frame() must be aligned to PAGE_SIZE.
				 *
				 * The function returns zero on success.
				 *
				 * Errors:
				 *  EDOM   - Attempt to push more physical frames to the framestack than available in the machine.
				 *  EFAULT - Address not aligned to PAGE_SIZE.
				 *
				 * Example:
				 * {
				 *     // Here is assumed PAGE_SIZE == 0x1000
				 *     // Here is assumed the kernel the frame: 0xf00f0000.
				 *     void* phys_addr = 0xf00f0000;
				 *
				 *     // Let's give it back
				 *     // 0xf00f0000 is pushed into the framestack.
				 *     int err = push_frames(phys_addr);
				 *     // taht page is no longer available and might be returned somewhere else in a future
				 *     // call to pop_frame().
				 * }
				 */

		The following functions shall define our vmalloc api:

			- void* vmalloc(size_t count)
				This function will allocate 'count' pages of physical memory and
				map them into the vmalloc area. Physical pages may be disconti-
				guous, but the virtual range will be contiguous.

				'count' must be non zero.

				This function will either return the address to a newly allocated
				memory region in the vmalloc area, or return an error.

				· ENOMEM → Not enough physical memory
				· EINVAL → Count is 0.

				Note that vmalloc area pointers are negative, such one can test
				for errors by ~~casting as signed and checking if 'x => 0'~~
				using the PTR_ERR() and PTR_AS_ERR() macros.

			- void vfree(void* vaddr, size_t count);

				This function takes 'count' contiguous virtual pages starting
				at vaddr and frees, walking the pagetables to get the physical
				addresses.

				'vaddr:count' must point to pages allocated with
				vmalloc().

				This function panic()s the system if 'vaddr:count' points to
				alteast one page that was not allocated with vmalloc().

Sample kernel mapping

0:      RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6A
0:      RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6B
253:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6C
91:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA5B
92:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA5C
93:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA5D
94:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA5E
95:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA5F
96:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA60
97:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA61
98:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA62
99:     RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA63
100:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA64
101:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA65
102:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA66
103:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA67
104:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA68
105:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA69
106:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6A
107:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6B
108:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6C
109:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6D
110:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6E
111:    RW: 1   UK: 1   AC: 0   PHY: 0x000000000001FA6F
